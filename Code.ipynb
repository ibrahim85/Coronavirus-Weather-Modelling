{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "from datetime import datetime,timedelta\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "from SEIR import corona_seir_model_population\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = ''           # Enter API key from https://darksky.net/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_null_vals(df,axis='both',subset=[]):\n",
    "    '''\n",
    "    Drops columns with all\n",
    "    nan values from a given \n",
    "    data frame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        DataFrame for which\n",
    "        columns are to be\n",
    "        dropped.\n",
    "        \n",
    "    axis : str\n",
    "        Drops all rows with\n",
    "        nan if axis=rows,\n",
    "        all columns if axis=columns,\n",
    "        and both if axis=both.\n",
    "        \n",
    "    subset : list of str\n",
    "        For all columns in\n",
    "        subset, remove the\n",
    "        NaN rows.\n",
    "    '''\n",
    "    assert(isinstance(df,pd.DataFrame))\n",
    "    assert(isinstance(axis,str))\n",
    "    assert(isinstance(subset,list))\n",
    "    assert(isinstance(col,str) for col in subset)\n",
    "    \n",
    "    df = df.dropna(subset=subset)\n",
    "    \n",
    "    if(axis=='rows'):\n",
    "        df = df.dropna(how='all',axis=0)\n",
    "    elif(axis=='columns'):\n",
    "        df = df.dropna(how='all',axis=1)\n",
    "    elif(axis=='both'):\n",
    "        df = df.dropna(how='all',axis=0).dropna(how='all',axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def getWeatherData(latitude,longitude,start_date,end_date):\n",
    "    '''\n",
    "    Returns temperature \n",
    "    and humidity data \n",
    "    as per the latitude \n",
    "    and longitude entered.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    latitude : float\n",
    "        Latitude of region\n",
    "        for fetching the\n",
    "        weather data\n",
    "        \n",
    "    longitude : float\n",
    "        Longitude of region\n",
    "        for fetching weather\n",
    "        data\n",
    "        \n",
    "    start_date : str\n",
    "        Start date to start \n",
    "        fetching weather data\n",
    "        from.\n",
    "        \n",
    "    end_date : str\n",
    "        End date to end \n",
    "        fetching weather data\n",
    "        at.\n",
    "    '''\n",
    "    assert(isinstance(latitude,float))\n",
    "    assert(isinstance(longitude,float))\n",
    "    assert(isinstance(start_date,str))\n",
    "    assert(isinstance(end_date,str))\n",
    "    \n",
    "    start_date = datetime.strptime(start_date,'%Y-%m-%d')\n",
    "    end_date = datetime.strptime(end_date,'%Y-%m-%d')\n",
    "    \n",
    "    day_count = (end_date - start_date).days + 1\n",
    "    temperature_list = []\n",
    "    humidity_list = []\n",
    "    \n",
    "    for single_date in (start_date + timedelta(n) for n in range(day_count)):\n",
    "        epoch_time = int(single_date.timestamp())\n",
    "        url = createWeatherURL(latitude,longitude,epoch_time)\n",
    "#         print(\"URL to get data: \",url)\n",
    "        response = requests.get(url)\n",
    "        lst = response.json()['hourly']['data']\n",
    "        temp_list = []\n",
    "        for l in lst:\n",
    "            temp_list.append(l['temperature'])\n",
    "    \n",
    "        mean_day_temperature = sum(temp_list)/len(temp_list)\n",
    "        temperature_list.append(mean_day_temperature)\n",
    "        humidity_list.append(response.json()['daily']['data'][0]['humidity'])\n",
    "        \n",
    "    return sum(temperature_list)/len(temperature_list),sum(humidity_list)/len(humidity_list)\n",
    "\n",
    "def createWeatherURL(latitude,longitude,epoch_time):\n",
    "    '''\n",
    "    Creates weather URL\n",
    "    for given latitude,\n",
    "    longitude and time.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    latitude : float\n",
    "        Latitude of the\n",
    "        region for which\n",
    "        data is to be fetched\n",
    "        \n",
    "    longitude : float\n",
    "        Longitude of the\n",
    "        region for which\n",
    "        data is to be fetched\n",
    "        \n",
    "    epoch_time : int\n",
    "        Time ending at which\n",
    "        data is to be fetched\n",
    "    '''\n",
    "    assert(isinstance(latitude,float))\n",
    "    assert(isinstance(longitude,float))\n",
    "    assert(isinstance(epoch_time,int))\n",
    "    \n",
    "    url = 'https://api.darksky.net/forecast/'+API_KEY+'/'+str(latitude)+','+str(longitude)+','+str(epoch_time)+'?exclude=currently,flags,minutely'\n",
    "\n",
    "    return url\n",
    "\n",
    "def getIndexByRegion(province,country,df):\n",
    "    '''\n",
    "    Gets index of a region\n",
    "    from a DataFrame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    province : str\n",
    "        Province for which\n",
    "        index is to be fetched\n",
    "        \n",
    "    Country : str\n",
    "        Country for which\n",
    "        index is to be fetched\n",
    "        \n",
    "    df : Pandas DataFrame\n",
    "        DataFrame from which\n",
    "        index is to be fetched\n",
    "    '''\n",
    "    assert(isinstance(country,str))\n",
    "    assert(isinstance(df,pd.DataFrame))\n",
    "    \n",
    "    if(type(province)!=str and np.isnan(province)):\n",
    "        idx = df[(df['Province/State'].isnull()) & (df['Country/Region']==country)].index\n",
    "        return idx.to_list()[0]\n",
    "    else:\n",
    "        idx = df[(df['Province/State']==province) & (df['Country/Region']==country)].index\n",
    "        return idx.to_list()[0]\n",
    "\n",
    "def fetch_province_country_by_region(region):\n",
    "    '''\n",
    "    Given a region as\n",
    "    Province,Country,\n",
    "    returns the province\n",
    "    and country or just\n",
    "    the country if no province\n",
    "    of the region.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    region : str\n",
    "        Region to be parsed\n",
    "    '''\n",
    "    assert(isinstance(region,str))\n",
    "    \n",
    "    result = region.split(\",\")\n",
    "    if(len(result)==2):\n",
    "        return result[0],result[1].strip()\n",
    "    else:\n",
    "        return np.NaN,region\n",
    "    \n",
    "def getPopulationByRegion(province,country,df):\n",
    "    '''\n",
    "    Given the province and\n",
    "    country of a region,\n",
    "    fetches the population\n",
    "    from the dataframe.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    province : str\n",
    "        Province for which\n",
    "        population is to be fetched\n",
    "        \n",
    "    Country : str\n",
    "        Country for which\n",
    "        population is to be fetched\n",
    "        \n",
    "    df : Pandas DataFrame\n",
    "        DataFrame from which\n",
    "        population is to be fetched\n",
    "    \n",
    "    '''\n",
    "    assert(isinstance(country,str))\n",
    "    assert(isinstance(df,pd.DataFrame))\n",
    "    \n",
    "    if(type(province)!=str and np.isnan(province)):\n",
    "        population = df[(df['Province/State'].isnull()) & (df['Country/Region']==country)].Population\n",
    "        return population.to_list()[0]\n",
    "    else:\n",
    "        population = df[(df['Province/State']==province) & (df['Country/Region']==country)].Population\n",
    "        return population.to_list()[0]\n",
    "    \n",
    "def getDatesByRegion(region,df):\n",
    "    '''\n",
    "    Given the province and\n",
    "    country of a region,\n",
    "    fetches the infection\n",
    "    duration from the dataframe.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    province : str\n",
    "        Province for which\n",
    "        dates are to be fetched\n",
    "        \n",
    "    Country : str\n",
    "        Country for which\n",
    "        dates are to be fetched\n",
    "        \n",
    "    df : Pandas DataFrame\n",
    "        DataFrame from which\n",
    "        dates are to be fetched\n",
    "    '''\n",
    "    assert(isinstance(region,str))\n",
    "    assert(isinstance(df,pd.DataFrame))\n",
    "    \n",
    "    region_row = df[df['Region']==region]\n",
    "    start_date = region_row['Time series start'].to_list()[0]\n",
    "    stop_date = region_row['Time series end'].to_list()[0]\n",
    "    \n",
    "    return start_date,stop_date\n",
    "\n",
    "def getLearningRate(region,df):\n",
    "    '''\n",
    "    Given the province and\n",
    "    country of a region,\n",
    "    fetches the learning\n",
    "    rate from the dataframe.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    province : str\n",
    "        Province for which\n",
    "        learning rate is\n",
    "        to be fetched\n",
    "        \n",
    "    Country : str\n",
    "        Country for which\n",
    "        learning rate is\n",
    "        to be fetched\n",
    "        \n",
    "    df : Pandas DataFrame\n",
    "        DataFrame from which\n",
    "        learning rate is\n",
    "        to be fetched\n",
    "    '''\n",
    "    assert(isinstance(region,str))\n",
    "    assert(isinstance(df,pd.DataFrame))\n",
    "    \n",
    "    region_row = df[df['Region']==region]\n",
    "    learning_rate = region_row['lr'].to_list()\n",
    "#     print(\"Learning rate:\",learning_rate)\n",
    "    if(math.isnan(learning_rate[0])):\n",
    "#         print(\"learning rate is null. returning 0.0004\")\n",
    "        return 0.0004\n",
    "    else:\n",
    "        return learning_rate[0]\n",
    "    \n",
    "def getWeatherDataForRegions(regions,time_series_confirmed,model_param_df):\n",
    "    '''\n",
    "    Given a list of regions,\n",
    "    returns the map of region\n",
    "    and its weather data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    regions : list\n",
    "        List of regions for\n",
    "        which data is to be\n",
    "        fetched.\n",
    "\n",
    "    time_series_confirmed : DataFrame\n",
    "        DataFrame that contains\n",
    "        time series data of\n",
    "        number of confirmed\n",
    "        cases all across the\n",
    "        world.\n",
    "        \n",
    "    model_param_df : DataFrame\n",
    "        DataFrame that contains\n",
    "        parameters of the model \n",
    "        and weather data.\n",
    "        \n",
    "    '''\n",
    "    assert(isinstance(regions,list))\n",
    "    assert(isinstance(time_series_confirmed,pd.DataFrame))\n",
    "    assert(isinstance(model_param_df,pd.DataFrame))\n",
    "    assert(all(isinstance(region,str) for region in regions))\n",
    "    \n",
    "    result = {}\n",
    "    \n",
    "    for region in regions:\n",
    "        try:\n",
    "            province,country = fetch_province_country_by_region(region)\n",
    "            region_idx = getIndexByRegion(province,country,time_series_confirmed)\n",
    "            latitude = time_series_confirmed.loc[region_idx]['Lat']\n",
    "            longitude = time_series_confirmed.loc[region_idx]['Long']\n",
    "            df = model_param_df[model_param_df['Region']==region]\n",
    "            start_date_index,end_date_index = getDatesByRegion(region,model_param_df)\n",
    "            start_date = str(datetime.strptime(time_series_confirmed.columns[start_date_index], '%m/%d/%Y').date())\n",
    "            end_date = str(datetime.strptime(time_series_confirmed.columns[end_date_index-1], '%m/%d/%Y').date())\n",
    "#             print('latitude,longitude=',str(latitude)+\",\"+str(longitude))\n",
    "#             print('start date= \"',start_date,end='\"\\n')\n",
    "#             print('end date= \"',end_date,end='\"\\n')\n",
    "            result[region] = getWeatherData(latitude,longitude,start_date,end_date)\n",
    "        except:\n",
    "            print(\"ERROR while fetching data for: \",region)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. population_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Population data of total population of a region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df = pd.read_csv(\"data/population_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. model_param_results.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters of different regions and their weather data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param_df = pd.read_csv('data/model_param_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Time series data (John Hopkins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series data of number of confirmed cases all across the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    confirmed_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "#     confirmed_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/archived_data/archived_time_series/time_series_19-covid-Confirmed_archived_0325.csv'\n",
    "    deaths_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv'\n",
    "#     deaths_url='https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/archived_data/archived_time_series/time_series_19-covid-Deaths_archived_0325.csv'\n",
    "    recovered_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv'\n",
    "#     recovered_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/archived_data/archived_time_series/time_series_19-covid-Recovered_archived_0325.csv'\n",
    "    \n",
    "    print('Fetching confirmed data from git...')\n",
    "    time_series_confirmed = drop_null_vals(pd.read_csv(confirmed_url,error_bad_lines=False))\n",
    "    print('Fetched confirmed data from git')\n",
    "    \n",
    "    time_series_confirmed.to_csv('data/time_series_covid_19_confirmed.csv')\n",
    "    \n",
    "    print('Fetching deaths data from git...')\n",
    "    time_series_deaths = drop_null_vals(pd.read_csv(deaths_url,error_bad_lines=False))\n",
    "    time_series_deaths.to_csv('data/time_series_covid_19_deaths.csv')\n",
    "    print('Fetched deaths data from git')\n",
    "    \n",
    "    print('Fetching recovered data from git...')\n",
    "    time_series_recovered = drop_null_vals(pd.read_csv(recovered_url,error_bad_lines=False))\n",
    "    time_series_recovered.to_csv('data/time_series_covid_19_recovered.csv')\n",
    "    print('Fetched recovered data from git')\n",
    "    \n",
    "except:\n",
    "    # data not able to be fetched from git, fetching from local system\n",
    "    print(\"Data not able to fetch from git. Using local filesystem.\")\n",
    "    time_series_confirmed = drop_null_vals(pd.read_csv('data/time_series_covid_19_confirmed.csv'))\n",
    "    time_series_deaths = drop_null_vals(pd.read_csv('data/time_series_covid_19_deaths.csv'))\n",
    "    time_series_recovered = drop_null_vals(pd.read_csv('data/time_series_covid_19_recovered.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_confirmed_coord = drop_null_vals(time_series_confirmed,subset=['Lat','Long'])\n",
    "series_confirmed_coord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature and humidity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = model_param_df['Region'].to_list()\n",
    "regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = getWeatherDataForRegions(regions,time_series_confirmed,model_param_df)\n",
    "\n",
    "with open('data/weather.json', 'w') as fp:\n",
    "    json.dump(result, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_to_data_population(model,gt_infected,population,region,count,df):\n",
    "\tT_max = gt_infected.shape[0]-1\n",
    "\tmax_infected = np.max(gt_infected)\n",
    "\tdt = 1\n",
    "\tT = np.linspace(0,T_max,int(T_max/dt)+1).astype(int)\n",
    "\tN = population\n",
    "\tinit_exposed = int(gt_infected[0]*2)\n",
    "\tinit_vals = (N-init_exposed-gt_infected[0]),init_exposed,gt_infected[0],0\n",
    "\tgamma2 = 0.03\n",
    "\trho = 1.0\n",
    "\ttotal_epochs = 20000\n",
    "\t# lr = 0.04\n",
    "\t# lrd = 0.01\n",
    "# \tlr = 0.0004/max_infected\n",
    "\tlr = getLearningRate(region,df)/max_infected\n",
    "# \tprint(\"learning rate: \",lr)\n",
    "\tlrd = 0.000\n",
    "\tcurr_params = 0.2,0.5,0.0,gamma2\n",
    "\tloss_arr = []\n",
    "\talpha_arr = []\n",
    "\tbeta_arr = []\n",
    "\tgamma1_arr = []\n",
    "\tgamma2_arr = []\n",
    "\tfor epoch in tqdm(range(total_epochs)):\n",
    "\t\tcurr_lr = lr/(1+epoch*lrd)\n",
    "\t\tloss_jacobian = epoch_fit_params_corona_seir_population(init_vals,curr_params,T,gt_infected,lr=curr_lr)\n",
    "\t\tloss_epoch = np.sum(loss_jacobian[0])\n",
    "\t\tnew_alpha = max(0,curr_params[0]+np.sum(loss_jacobian[1]))\n",
    "\t\tnew_beta = max(0,curr_params[1]+np.sum(loss_jacobian[2]))\n",
    "\t\tnew_gamma1 = max(0,curr_params[2]+np.sum(loss_jacobian[3]))\n",
    "\t\tnew_gamma2 = max(0,curr_params[3]+np.sum(loss_jacobian[4]))\n",
    "\t\tcurr_params = new_alpha,new_beta,new_gamma1,new_gamma2\n",
    "\t\tloss_arr.append(loss_epoch)\n",
    "\t\talpha_arr.append(new_alpha)\n",
    "\t\tbeta_arr.append(new_beta)\n",
    "\t\tgamma1_arr.append(new_gamma1)\n",
    "\t\tgamma2_arr.append(new_gamma2)\n",
    "\tbest_epoch = np.argmin(np.array(loss_arr))\n",
    "\tprint(\"Best learned params: {} {} {}\".format(alpha_arr[best_epoch],beta_arr[best_epoch],gamma1_arr[best_epoch]))\n",
    "\tplt.figure(count)\n",
    "\tplt.subplot(221)\n",
    "\tplt.axvline(x=best_epoch,color='k',linestyle='--')\n",
    "\tplt.plot(list(range(total_epochs)),loss_arr)\n",
    "\tplt.ylabel('Total MSE loss')\n",
    "\tplt.xlabel('Epochs')\n",
    "\tplt.subplot(222)\n",
    "\tplt.axvline(x=best_epoch,color='k',linestyle='--')\n",
    "\tplt.plot(list(range(total_epochs)),alpha_arr,label='alpha')\n",
    "\tplt.plot(list(range(total_epochs)),beta_arr,label='beta')\n",
    "\tplt.plot(list(range(total_epochs)),gamma1_arr,label='gamma1')\n",
    "\t# plt.plot(list(range(total_epochs)),gamma2_arr,label='gamma2')\n",
    "\tplt.title('Learning trajectory for '+region)\n",
    "\tplt.ylabel('Parameter value')\n",
    "\tplt.xlabel('Epochs')\n",
    "\tplt.legend()\n",
    "\t# print(init_vals)\n",
    "\tbest_params = alpha_arr[best_epoch],beta_arr[best_epoch],gamma1_arr[best_epoch],gamma2\n",
    "\tT_pred = np.linspace(0,10+T_max,int((10+T_max)/dt)+1).astype(int)\n",
    "\tlearned_results = model(init_vals,best_params,T_pred)\n",
    "\t# plt.figure(2)\n",
    "\tplt.subplot(212)\n",
    "\t# p = plt.plot(T,sim_results[0],label='GT Susceptible')\n",
    "\t# p = plt.plot(T_pred,learned_results[0]/N,linestyle='--',label='Predicted Susceptible')\n",
    "\t# p = plt.plot(T,sim_results[1],label='GT Exposed')\n",
    "\t# p = plt.plot(T_pred,learned_results[1]/N,linestyle='--',label='Predicted Exposed')\n",
    "\tp = plt.plot(gt_infected[T]/N,label='GT Infected')\n",
    "\tplt.plot(T_pred,learned_results[2]/N,color=p[0].get_color(),linestyle='--',label='Predicted Infected')\n",
    "\tprint(\"error percentage : \",region,abs(100*(learned_results[2][len(gt_infected)-1]-gt_infected[-1])/gt_infected[-1]))\n",
    "\t# p = plt.plot(T,sim_results[3],label='Recovered')\n",
    "\tp = plt.plot(T_pred,learned_results[3]/N,linestyle='--',label='Predicted Recovered')\n",
    "\tplt.legend()\n",
    "\tplt.ylabel('Fraction of population')\n",
    "\tplt.xlabel('Time (days)')\n",
    "\tplt.title('GT and learned models')\n",
    "\tplt.show()\n",
    "    \n",
    "def epoch_fit_params_corona_seir_population(init_vals, init_params, T, infected, lr=1e-2):\n",
    "\tmax_infected = np.max(infected)\n",
    "\tS0,E0,I0,R0 = init_vals\n",
    "\tN = S0+E0+I0+R0\n",
    "\tS, E, I , R = [S0], [E0], [I0], [R0]\n",
    "\tloss = [0]\n",
    "\talpha, beta, gamma1, gamma2 = init_params\n",
    "\tdt = T[1]-T[0]\n",
    "\tjacobian_mat = np.zeros((3,4))\n",
    "\t# updated_alpha, updated_beta, updated_gamma1, updated_gamma2 = [alpha],[beta],[gamma1],[gamma2]\n",
    "\tupdate_alpha, update_beta, update_gamma1, update_gamma2 = [0],[0],[0],[0]\n",
    "\t# print(infected)\n",
    "\tfor idx,t in enumerate(T[1:-3]):\n",
    "\t\t# print(\"{} {} {} {} {:.3f} {:.3f} {:.3f} {:3.3f}\".format(t,alpha,beta,gamma1,S[-1],E[-1],I[-1],np.max(jacobian_mat)))\n",
    "\t\tupdate_mat = np.array([[(1-beta*E[-1]/N),(-beta*S[-1]/N),0],[(beta*E[-1]/N),(1+beta*S[-1]/N-alpha-gamma1),0],[0,alpha,(1-gamma2)]])\n",
    "\t\tadd_mat = np.array([[0,(-S[-1]*(E[-1]/N)),0,0],[(-E[-1]),S[-1]*(E[-1]/N),(-E[-1]),0],[E[-1],0,0,(-I[-1])]])/max_infected\n",
    "\t\tjacobian_mat = np.matmul(update_mat,jacobian_mat)+add_mat\n",
    "\t\tmin_val = N\n",
    "\t\tS1 = S[-1] - (beta*S[-1]*E[-1]/N)*dt\n",
    "\t\tif S1<min_val: min_val=S1\n",
    "\t\tE1 = E[-1] + (beta*S[-1]*E[-1]/N - alpha*E[-1] - gamma1*E[-1])*dt\n",
    "\t\tif E1<min_val: min_val=E1\n",
    "\t\tI1 = I[-1] + (alpha*E[-1] - gamma2*I[-1])*dt\n",
    "\t\tif I1<min_val: min_val=I1\n",
    "\t\tR1 = R[-1] + (gamma1*E[-1] + gamma2*I[-1])*dt\n",
    "\t\tif R1<min_val: min_val=R1\n",
    "\t\tN1 = S1+E1+I1+R1-4*min_val\n",
    "\t\tS1 = N*(S1-min_val)/N1\n",
    "\t\tE1 = N*(E1-min_val)/N1\n",
    "\t\tI1 = N*(I1-min_val)/N1\n",
    "\t\tR1 = N*(R1-min_val)/N1\n",
    "\t\tS.append(S1)\n",
    "\t\tE.append(E1)\n",
    "\t\tI.append(I1)\n",
    "\t\tR.append(R1)\n",
    "\t\t# print(T[idx+1],infected[T[idx+1]])\n",
    "\t\tloss.append(((infected[T[idx+1]]-I1)**2)**0.5)\n",
    "\t\talpha_update = lr*(infected[T[idx+1]]-I1)*jacobian_mat[2,0]\n",
    "\t\tbeta_update = lr*(infected[T[idx+1]]-I1)*jacobian_mat[2,1]\n",
    "\t\tgamma1_update = 0 #lr*(infected[T[idx+1]]-I1)*jacobian_mat[2,2]\n",
    "\t\tgamma2_update = 0 #lr*(infected[idx+1]-I1)*jacobian_mat[2,3]\n",
    "\t\talpha_new = alpha+alpha_update\n",
    "\t\tbeta_new = beta+beta_update\n",
    "\t\tgamma1_new = gamma1+gamma1_update\n",
    "\t\tgamma2_new = gamma2+gamma2_update\n",
    "\t\tupdate_alpha.append(alpha_update)\n",
    "\t\tupdate_beta.append(beta_update)\n",
    "\t\tupdate_gamma1.append(gamma1_update)\n",
    "\t\tupdate_gamma2.append(gamma2_update)\n",
    "\t# return np.stack([loss,alpha_vals_S,alpha_vals_E,alpha_vals_I])\n",
    "\treturn np.stack([loss,update_alpha,update_beta,update_gamma1,update_gamma2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for region in regions:\n",
    "    try:\n",
    "        province,country =fetch_province_country_by_region(region)\n",
    "#         print(province,country)\n",
    "        region_idx = getIndexByRegion(province,country,time_series_confirmed)\n",
    "#         print(region_idx)\n",
    "        region_population = int(getPopulationByRegion(province,country,population_df))\n",
    "#         print(region_population)\n",
    "        time_series_start,time_series_end = getDatesByRegion(region,model_param_df)\n",
    "#         print(getDatesByRegion(region,model_param_df))\n",
    "        data = time_series_confirmed\n",
    "        gt_infected = np.array(data.iloc[region_idx,time_series_start:time_series_end]).astype(int)\n",
    "        plt.figure(count)\n",
    "#         plt.plot(gt_infected); plt.show()\n",
    "        fit_to_data_population(corona_seir_model_population,gt_infected,region_population,region,count,model_param_df)\n",
    "        count+=1\n",
    "    except:\n",
    "        print(\"No data found for %s,%s\"%(province,country))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
