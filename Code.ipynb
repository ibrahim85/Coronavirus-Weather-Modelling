{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "from datetime import datetime,timedelta\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "from SEIR import corona_seir_model_population\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = ''           # Enter API key from https://darksky.net/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_null_vals(df,axis='both',subset=[]):\n",
    "    '''\n",
    "    Drops columns with all\n",
    "    nan values from a given \n",
    "    data frame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        DataFrame for which\n",
    "        columns are to be\n",
    "        dropped.\n",
    "        \n",
    "    axis : str\n",
    "        Drops all rows with\n",
    "        nan if axis=rows,\n",
    "        all columns if axis=columns,\n",
    "        and both if axis=both.\n",
    "        \n",
    "    subset : list of str\n",
    "        For all columns in\n",
    "        subset, remove the\n",
    "        NaN rows.\n",
    "    '''\n",
    "    assert(isinstance(df,pd.DataFrame))\n",
    "    assert(isinstance(axis,str))\n",
    "    assert(isinstance(subset,list))\n",
    "    assert(isinstance(col,str) for col in subset)\n",
    "    \n",
    "    df = df.dropna(subset=subset)\n",
    "    \n",
    "    if(axis=='rows'):\n",
    "        df = df.dropna(how='all',axis=0)\n",
    "    elif(axis=='columns'):\n",
    "        df = df.dropna(how='all',axis=1)\n",
    "    elif(axis=='both'):\n",
    "        df = df.dropna(how='all',axis=0).dropna(how='all',axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def getWeatherData(latitude,longitude,start_date,end_date):\n",
    "    '''\n",
    "    Returns temperature \n",
    "    and humidity data \n",
    "    as per the latitude \n",
    "    and longitude entered.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    latitude : float\n",
    "        Latitude of region\n",
    "        for fetching the\n",
    "        weather data\n",
    "        \n",
    "    longitude : float\n",
    "        Longitude of region\n",
    "        for fetching weather\n",
    "        data\n",
    "        \n",
    "    start_date : str\n",
    "        Start date to start \n",
    "        fetching weather data\n",
    "        from.\n",
    "        \n",
    "    end_date : str\n",
    "        End date to end \n",
    "        fetching weather data\n",
    "        at.\n",
    "    '''\n",
    "    assert(isinstance(latitude,float))\n",
    "    assert(isinstance(longitude,float))\n",
    "    assert(isinstance(start_date,str))\n",
    "    assert(isinstance(end_date,str))\n",
    "    \n",
    "    start_date = datetime.strptime(start_date,'%Y-%m-%d')\n",
    "    end_date = datetime.strptime(end_date,'%Y-%m-%d')\n",
    "    \n",
    "    day_count = (end_date - start_date).days + 1\n",
    "    temperature_list = []\n",
    "    humidity_list = []\n",
    "    \n",
    "    for single_date in (start_date + timedelta(n) for n in range(day_count)):\n",
    "        epoch_time = int(single_date.timestamp())\n",
    "        url = createWeatherURL(latitude,longitude,epoch_time)\n",
    "#         print(\"URL to get data: \",url)\n",
    "        response = requests.get(url)\n",
    "        lst = response.json()['hourly']['data']\n",
    "        temp_list = []\n",
    "        for l in lst:\n",
    "            temp_list.append(l['temperature'])\n",
    "    \n",
    "        mean_day_temperature = sum(temp_list)/len(temp_list)\n",
    "        temperature_list.append(mean_day_temperature)\n",
    "        humidity_list.append(response.json()['daily']['data'][0]['humidity'])\n",
    "        \n",
    "    return sum(temperature_list)/len(temperature_list),sum(humidity_list)/len(humidity_list)\n",
    "\n",
    "def createWeatherURL(latitude,longitude,epoch_time):\n",
    "    '''\n",
    "    Creates weather URL\n",
    "    for given latitude,\n",
    "    longitude and time.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    latitude : float\n",
    "        Latitude of the\n",
    "        region for which\n",
    "        data is to be fetched\n",
    "        \n",
    "    longitude : float\n",
    "        Longitude of the\n",
    "        region for which\n",
    "        data is to be fetched\n",
    "        \n",
    "    epoch_time : int\n",
    "        Time ending at which\n",
    "        data is to be fetched\n",
    "    '''\n",
    "    assert(isinstance(latitude,float))\n",
    "    assert(isinstance(longitude,float))\n",
    "    assert(isinstance(epoch_time,int))\n",
    "    \n",
    "    url = 'https://api.darksky.net/forecast/'+API_KEY+'/'+str(latitude)+','+str(longitude)+','+str(epoch_time)+'?exclude=currently,flags,minutely'\n",
    "\n",
    "    return url\n",
    "\n",
    "def getIndexByRegion(province,country,df):\n",
    "    '''\n",
    "    Gets index of a region\n",
    "    from a DataFrame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    province : str\n",
    "        Province for which\n",
    "        index is to be fetched\n",
    "        \n",
    "    Country : str\n",
    "        Country for which\n",
    "        index is to be fetched\n",
    "        \n",
    "    df : Pandas DataFrame\n",
    "        DataFrame from which\n",
    "        index is to be fetched\n",
    "    '''\n",
    "    assert(isinstance(country,str))\n",
    "    assert(isinstance(df,pd.DataFrame))\n",
    "    \n",
    "    if(type(province)!=str and np.isnan(province)):\n",
    "        idx = df[(df['Province/State'].isnull()) & (df['Country/Region']==country)].index\n",
    "        return idx.to_list()[0]\n",
    "    else:\n",
    "        idx = df[(df['Province/State']==province) & (df['Country/Region']==country)].index\n",
    "        return idx.to_list()[0]\n",
    "\n",
    "def fetch_province_country_by_region(region):\n",
    "    '''\n",
    "    Given a region as\n",
    "    Province,Country,\n",
    "    returns the province\n",
    "    and country or just\n",
    "    the country if no province\n",
    "    of the region.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    region : str\n",
    "        Region to be parsed\n",
    "    '''\n",
    "    assert(isinstance(region,str))\n",
    "    \n",
    "    result = region.split(\",\")\n",
    "    if(len(result)==2):\n",
    "        return result[0],result[1].strip()\n",
    "    else:\n",
    "        return np.NaN,region\n",
    "    \n",
    "def getPopulationByRegion(province,country,df):\n",
    "    '''\n",
    "    Given the province and\n",
    "    country of a region,\n",
    "    fetches the population\n",
    "    from the dataframe.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    province : str\n",
    "        Province for which\n",
    "        population is to be fetched\n",
    "        \n",
    "    Country : str\n",
    "        Country for which\n",
    "        population is to be fetched\n",
    "        \n",
    "    df : Pandas DataFrame\n",
    "        DataFrame from which\n",
    "        population is to be fetched\n",
    "    \n",
    "    '''\n",
    "    assert(isinstance(country,str))\n",
    "    assert(isinstance(df,pd.DataFrame))\n",
    "    \n",
    "    if(type(province)!=str and np.isnan(province)):\n",
    "        population = df[(df['Province/State'].isnull()) & (df['Country/Region']==country)].Population\n",
    "        return population.to_list()[0]\n",
    "    else:\n",
    "        population = df[(df['Province/State']==province) & (df['Country/Region']==country)].Population\n",
    "        return population.to_list()[0]\n",
    "    \n",
    "def getDatesByRegion(region,df):\n",
    "    '''\n",
    "    Given the province and\n",
    "    country of a region,\n",
    "    fetches the infection\n",
    "    duration from the dataframe.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    province : str\n",
    "        Province for which\n",
    "        dates are to be fetched\n",
    "        \n",
    "    Country : str\n",
    "        Country for which\n",
    "        dates are to be fetched\n",
    "        \n",
    "    df : Pandas DataFrame\n",
    "        DataFrame from which\n",
    "        dates are to be fetched\n",
    "    '''\n",
    "    assert(isinstance(region,str))\n",
    "    assert(isinstance(df,pd.DataFrame))\n",
    "    \n",
    "    region_row = df[df['Region']==region]\n",
    "    start_date = region_row['Time series start'].to_list()[0]\n",
    "    stop_date = region_row['Time series end'].to_list()[0]\n",
    "    \n",
    "    return start_date,stop_date\n",
    "\n",
    "def getLearningRate(region,df):\n",
    "    '''\n",
    "    Given the province and\n",
    "    country of a region,\n",
    "    fetches the learning\n",
    "    rate from the dataframe.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    province : str\n",
    "        Province for which\n",
    "        learning rate is\n",
    "        to be fetched\n",
    "        \n",
    "    Country : str\n",
    "        Country for which\n",
    "        learning rate is\n",
    "        to be fetched\n",
    "        \n",
    "    df : Pandas DataFrame\n",
    "        DataFrame from which\n",
    "        learning rate is\n",
    "        to be fetched\n",
    "    '''\n",
    "    assert(isinstance(region,str))\n",
    "    assert(isinstance(df,pd.DataFrame))\n",
    "    \n",
    "    region_row = df[df['Region']==region]\n",
    "    learning_rate = region_row['lr'].to_list()\n",
    "#     print(\"Learning rate:\",learning_rate)\n",
    "    if(math.isnan(learning_rate[0])):\n",
    "#         print(\"learning rate is null. returning 0.0004\")\n",
    "        return 0.0004\n",
    "    else:\n",
    "        return learning_rate[0]\n",
    "    \n",
    "def getWeatherDataForRegions(regions,time_series_confirmed,model_param_df):\n",
    "    '''\n",
    "    Given a list of regions,\n",
    "    returns the map of region\n",
    "    and its weather data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    regions : list\n",
    "        List of regions for\n",
    "        which data is to be\n",
    "        fetched.\n",
    "\n",
    "    time_series_confirmed : DataFrame\n",
    "        DataFrame that contains\n",
    "        time series data of\n",
    "        number of confirmed\n",
    "        cases all across the\n",
    "        world.\n",
    "        \n",
    "    model_param_df : DataFrame\n",
    "        DataFrame that contains\n",
    "        parameters of the model \n",
    "        and weather data.\n",
    "        \n",
    "    '''\n",
    "    assert(isinstance(regions,list))\n",
    "    assert(isinstance(time_series_confirmed,pd.DataFrame))\n",
    "    assert(isinstance(model_param_df,pd.DataFrame))\n",
    "    assert(all(isinstance(region,str) for region in regions))\n",
    "    \n",
    "    result = {}\n",
    "    \n",
    "    for region in regions:\n",
    "        try:\n",
    "            province,country = fetch_province_country_by_region(region)\n",
    "            region_idx = getIndexByRegion(province,country,time_series_confirmed)\n",
    "            latitude = time_series_confirmed.loc[region_idx]['Lat']\n",
    "            longitude = time_series_confirmed.loc[region_idx]['Long']\n",
    "            df = model_param_df[model_param_df['Region']==region]\n",
    "            start_date_index,end_date_index = getDatesByRegion(region,model_param_df)\n",
    "            start_date = str(datetime.strptime(time_series_confirmed.columns[start_date_index], '%m/%d/%Y').date())\n",
    "            end_date = str(datetime.strptime(time_series_confirmed.columns[end_date_index-1], '%m/%d/%Y').date())\n",
    "#             print('latitude,longitude=',str(latitude)+\",\"+str(longitude))\n",
    "#             print('start date= \"',start_date,end='\"\\n')\n",
    "#             print('end date= \"',end_date,end='\"\\n')\n",
    "            result[region] = getWeatherData(latitude,longitude,start_date,end_date)\n",
    "        except:\n",
    "            print(\"ERROR while fetching data for: \",region)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. population_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Population data of total population of a region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df = pd.read_csv(\"data/population_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. model_param_results.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters of different regions and their weather data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param_df = pd.read_csv('data/model_param_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Time series data (John Hopkins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series data of number of confirmed cases all across the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    confirmed_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "#     confirmed_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/archived_data/archived_time_series/time_series_19-covid-Confirmed_archived_0325.csv'\n",
    "    deaths_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv'\n",
    "#     deaths_url='https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/archived_data/archived_time_series/time_series_19-covid-Deaths_archived_0325.csv'\n",
    "    recovered_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv'\n",
    "#     recovered_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/archived_data/archived_time_series/time_series_19-covid-Recovered_archived_0325.csv'\n",
    "    \n",
    "    print('Fetching confirmed data from git...')\n",
    "    time_series_confirmed = drop_null_vals(pd.read_csv(confirmed_url,error_bad_lines=False))\n",
    "    print('Fetched confirmed data from git')\n",
    "    \n",
    "    time_series_confirmed.to_csv('data/time_series_covid_19_confirmed.csv')\n",
    "    \n",
    "    print('Fetching deaths data from git...')\n",
    "    time_series_deaths = drop_null_vals(pd.read_csv(deaths_url,error_bad_lines=False))\n",
    "    time_series_deaths.to_csv('data/time_series_covid_19_deaths.csv')\n",
    "    print('Fetched deaths data from git')\n",
    "    \n",
    "    print('Fetching recovered data from git...')\n",
    "    time_series_recovered = drop_null_vals(pd.read_csv(recovered_url,error_bad_lines=False))\n",
    "    time_series_recovered.to_csv('data/time_series_covid_19_recovered.csv')\n",
    "    print('Fetched recovered data from git')\n",
    "    \n",
    "except:\n",
    "    # data not able to be fetched from git, fetching from local system\n",
    "    print(\"Data not able to fetch from git. Using local filesystem.\")\n",
    "    time_series_confirmed = drop_null_vals(pd.read_csv('data/time_series_covid_19_confirmed.csv'))\n",
    "    time_series_deaths = drop_null_vals(pd.read_csv('data/time_series_covid_19_deaths.csv'))\n",
    "    time_series_recovered = drop_null_vals(pd.read_csv('data/time_series_covid_19_recovered.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_confirmed_coord = drop_null_vals(time_series_confirmed,subset=['Lat','Long'])\n",
    "series_confirmed_coord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature and humidity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = model_param_df['Region'].to_list()\n",
    "regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = getWeatherDataForRegions(regions,time_series_confirmed,model_param_df)\n",
    "\n",
    "with open('data/weather.json', 'w') as fp:\n",
    "    json.dump(result, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
